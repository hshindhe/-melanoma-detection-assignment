{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yDriIbfa5lwD"
   },
   "source": [
    "Problem statement: To build a CNN based model which can accurately detect melanoma. Melanoma is a type of cancer that can be deadly if not detected early. It accounts for 75% of skin cancer deaths. A solution which can evaluate images and alert the dermatologists about the presence of melanoma has the potential to reduce a lot of manual effort needed in diagnosis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JfcpIXQZN2Rh"
   },
   "source": [
    "### Importing all the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "WC8xCQuELWms"
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-3-5c0cc89139fd>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-3-5c0cc89139fd>\"\u001b[1;36m, line \u001b[1;32m3\u001b[0m\n\u001b[1;33m    pip install tensorflow == 1.5.0\u001b[0m\n\u001b[1;37m        ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import PIL\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np, pandas as pd\n",
    "\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lvR7ppk77v31"
   },
   "source": [
    "### Importing Skin Cancer Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RpUsRQwOOL72"
   },
   "source": [
    "This assignment uses a dataset of about 2357 images of skin cancer types. The dataset contains 9 sub-directories in each train and test subdirectories. The 9 sub-directories contains the images of 9 skin cancer types respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-jKb5LRKNYKE",
    "outputId": "0d0eb683-0c07-4298-ed01-255238d7f7b4"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "D57L-ovIKtI4"
   },
   "outputs": [],
   "source": [
    "import pathlib\n",
    "\n",
    "# Defining the path for train and test images\n",
    "data_dir_train = pathlib.Path(\"Colab Notebooks/Train\")\n",
    "data_dir_test = pathlib.Path('CColab Notebooks/Test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DqksN1w5Fu-N",
    "outputId": "653297cd-ed5c-40dd-ecc7-beb0bcedc69f"
   },
   "outputs": [],
   "source": [
    "# Retrieve all the images available in train dataset\n",
    "img_count_train = len(list(data_dir_train.glob(\"*/*.jpg\")))\n",
    "print(img_count_train)\n",
    "\n",
    "# Retrieve all the images available in test dataset\n",
    "img_count_test = len(list(data_dir_test.glob(\"*/*.jpg\")))\n",
    "print(img_count_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O8HkfW3jPJun"
   },
   "source": [
    "### Load using keras.preprocessing\n",
    "\n",
    "Let's load these images off disk using the helpful image_dataset_from_directory utility."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cDBKZG3jPcMc"
   },
   "source": [
    "### Create a dataset\n",
    "\n",
    "Defining the parameters for the loader:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VLfcXcZ9LjGv"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y5f5y43GPog1"
   },
   "source": [
    "Use 80% of the images for training, and 20% for validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "G1BWmDzr7w-5",
    "outputId": "9ecb222e-7309-4d84-eb4e-1c69d61a1cb2"
   },
   "outputs": [],
   "source": [
    "# Training data\n",
    "\n",
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'training',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYch6-SR-i2g",
    "outputId": "ceb2d204-8c12-4840-e009-3bae2f69a0d5"
   },
   "outputs": [],
   "source": [
    "# Validation data\n",
    "\n",
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'validation',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Bk0RV7G7-nad",
    "outputId": "81811260-3c0c-4a07-e6ca-58490143a672"
   },
   "outputs": [],
   "source": [
    "# Listing out all the 9 classes of skin cancer and then storing them in a list.\n",
    "\n",
    "class_names = train_ds.class_names\n",
    "print(class_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jbsm5oYiQH_b"
   },
   "source": [
    "### Visualize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 983
    },
    "id": "tKILZ48I-q1k",
    "outputId": "b2eb37e8-85c7-4e33-a2ed-9fb7874494fb"
   },
   "outputs": [],
   "source": [
    "# Visualizing classes\n",
    "\n",
    "plt.figure(figsize=(12, 12))\n",
    "for images, labels in train_ds.take(1):\n",
    "  for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.title(class_names[labels[i]])\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(images[i].numpy().astype(\"uint8\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8cAZPYaeQjQy"
   },
   "source": [
    "The `image_batch` is a tensor of the shape `(32, 180, 180, 3)`. This is a batch of 32 images of shape `180x180x3` (the last dimension refers to color channels RGB). The `label_batch` is a tensor of the shape `(32,)`, these are corresponding labels to the 32 images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jzVXBHiyQ7_I"
   },
   "source": [
    "`Dataset.cache()` keeps the images in memory after they're loaded off disk during the first epoch.\n",
    "\n",
    "`Dataset.prefetch()` overlaps data preprocessing and model execution while training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7wZlKRBEGNtU"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1JEAF6-sRyz8"
   },
   "source": [
    "### Create the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ync9xoW7GZgn"
   },
   "outputs": [],
   "source": [
    "classes = 9\n",
    "\n",
    "model1 = Sequential([\n",
    "  layers.Rescaling(1./255, input_shape=(img_height, img_width, 3)),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SDKzJmHwSCtt"
   },
   "source": [
    "### Compile the model\n",
    "We will be using adam optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OvYgY6FJO87M"
   },
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model1.compile(optimizer='adam',\n",
    "               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_ZGWN4MZGhtJ",
    "outputId": "ae116c2a-baa2-4f50-ad91-8bbdde7399a2"
   },
   "outputs": [],
   "source": [
    "# View the summary of all layers\n",
    "model1.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ljD_83rwSl5O"
   },
   "source": [
    "### Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Kkfw2rJXGlYC",
    "outputId": "7007689e-7d9b-4df8-f7cb-e34148c60686"
   },
   "outputs": [],
   "source": [
    "epochs = 20\n",
    "history = model1.fit(\n",
    "  train_ds,\n",
    "  validation_data=val_ds,\n",
    "  epochs=epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "w3679V8OShSE"
   },
   "source": [
    "### Visualizing training results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R1xkgk5nGubz"
   },
   "outputs": [],
   "source": [
    "def results(history):\n",
    "  acc = history.history['accuracy']\n",
    "  val_acc = history.history['val_accuracy']\n",
    "\n",
    "  loss = history.history['loss']\n",
    "  val_loss = history.history['val_loss']\n",
    "\n",
    "  epochs_range = range(epochs)\n",
    "\n",
    "  plt.figure(figsize=(8, 8))\n",
    "  plt.subplot(1, 2, 1)\n",
    "  plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "  plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "  plt.legend(loc='lower right')\n",
    "  plt.title('Training and Validation Accuracy')\n",
    "\n",
    "  plt.subplot(1, 2, 2)\n",
    "  plt.plot(epochs_range, loss, label='Training Loss')\n",
    "  plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "  plt.legend(loc='upper right')\n",
    "  plt.title('Training and Validation Loss')\n",
    "  plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "6uRRv8-UQaKv",
    "outputId": "54054fd9-4a3a-4793-cd42-1bae68f5a07b"
   },
   "outputs": [],
   "source": [
    "results(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JvPphJYuSZhK"
   },
   "source": [
    "The graph shows that training accuracy is much higher than validation accuracy. We can also notice differences in loss functions in training and validation data. This is a clear instance of overfitting, in which the model learnt too much from the training dataset and is unable to perform well on the validation dataset.\n",
    "\n",
    "**Training Accuracy:** 90.82 &\n",
    "**Validation Accuracy:** 52.80"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FGOHUb1MQxO3"
   },
   "source": [
    "### Creating next model with augmented strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "22hljAl6GykA"
   },
   "outputs": [],
   "source": [
    "# Data Augumentation\n",
    "\n",
    "data_augmentation = keras.Sequential(\n",
    "  [\n",
    "    layers.RandomFlip(\"horizontal\",\n",
    "                      input_shape=(img_height,\n",
    "                                   img_width,\n",
    "                                   3)),\n",
    "    layers.RandomRotation(0.1),\n",
    "    layers.RandomZoom(0.1),\n",
    "  ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XhKDHlUdTuSX"
   },
   "source": [
    "### Create the model, compile and train the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XEjPWh8GG0C7"
   },
   "outputs": [],
   "source": [
    "# Using Dropout layer for handling overfitting\n",
    "\n",
    "model2 = Sequential([\n",
    "  data_augmentation,\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FfUWFp96UIAN"
   },
   "source": [
    "### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_-7yTm8IG8zR"
   },
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam',\n",
    "               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ICLdZuhuRyMI",
    "outputId": "969c48bd-d8f4-4cca-d2e9-4e824e2190a7"
   },
   "outputs": [],
   "source": [
    "# Viewing the summary of model\n",
    "model2.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kC-D_RWOURp6"
   },
   "source": [
    "### Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UcPfkUASHBf9",
    "outputId": "c97b7376-b1d5-425e-b90a-64b295f14654"
   },
   "outputs": [],
   "source": [
    "#Training the model for ~20 epochs\n",
    "epochs = 20\n",
    "\n",
    "history_1 = model2.fit(train_ds,\n",
    "                       validation_data=val_ds,\n",
    "                       epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IhNOKtSyUYzC"
   },
   "source": [
    "### Visualizing the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "vjN_F4QxHIsh",
    "outputId": "0e9b8059-c86c-49fd-e2bc-6972e7b2f8c1"
   },
   "outputs": [],
   "source": [
    "results(history_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0-AUR_b7UcaK"
   },
   "source": [
    "1. Post this, Training accuracy has not increased when compared to the first model.\n",
    "2. However there is very less difference between training and validation accuracy.\n",
    "3. There is very marginal improvement in the Validation accuracy compared to the first model.\n",
    "4. Training loss and Validation loss has very less difference.\n",
    "5. And we see that overfitting has been decreased as a result of data augmentation.\n",
    "\n",
    "**Training Accuracy:** 64.63 &\n",
    "**Validation Accuracy:** 54.81"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7TdDi4u-VTkW"
   },
   "source": [
    "Class Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "HAhwYgtTQRzq",
    "outputId": "bb3fe28f-17f5-4bf5-f62e-7a5246851910"
   },
   "outputs": [],
   "source": [
    "# Ploting the number of images in each Class\n",
    "count=[]\n",
    "for name in class_names:\n",
    "    count.append(len(list(data_dir_train.glob(name+'/*.jpg'))))\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.bar(class_names,count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4csQL1dvO0b2"
   },
   "source": [
    "**Insights:**\n",
    "\n",
    "\n",
    "1.   ***Seborrheic keratosi class has the least number of samples.***\n",
    "2.   ***Pigmented Benign keratosis class has the most number of samples***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ItAg4rU-SzJh",
    "outputId": "7ce68fd0-bc43-4ace-b200-7b0ee829380a"
   },
   "outputs": [],
   "source": [
    "!pip install Augmentor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZKzTe3zWL4O"
   },
   "source": [
    "To use `Augmentor`, the following general procedure is followed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9Egt9EHjR-Dd",
    "outputId": "44e58398-8ffa-4fc6-decb-067d651a3336"
   },
   "outputs": [],
   "source": [
    "import Augmentor\n",
    "\n",
    "path_to_training_dataset=str(data_dir_train)+'/'\n",
    "for i in class_names:\n",
    "    p = Augmentor.Pipeline(path_to_training_dataset + i)\n",
    "    p.rotate(probability=0.7, max_left_rotation=10, max_right_rotation=10)\n",
    "    p.sample(500) ## We are adding 500 samples per class to make sure that none of the classes are sparse."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 281
    },
    "id": "Pl7KPVNeS0YO",
    "outputId": "4d3fa743-f895-44f2-bc42-02fbbb24158c"
   },
   "outputs": [],
   "source": [
    "# Checking the distribution of data\n",
    "count=[]\n",
    "for name in class_names:\n",
    "    count.append(len(list(data_dir_train.glob(name+'*/output/*.jpg'))))\n",
    "plt.figure(figsize=(25,5))\n",
    "plt.bar(class_names,count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CcBIFZGbWuFa"
   },
   "source": [
    "Augmentor has stored the augmented images in the output sub-directory of each of the sub-directories of skin cancer types.. Lets take a look at total count of augmented images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jxWcMqZhdRWz",
    "outputId": "d7a28aaa-134a-4662-fd5a-5548d1f8a9a7"
   },
   "outputs": [],
   "source": [
    "image_count_train = len(list(data_dir_train.glob('*/output/*.jpg')))\n",
    "print(image_count_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IJ5KarKq4kWJ"
   },
   "source": [
    "### Lets see the distribution of augmented data after adding new images to the original training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6tODrYIY2nxJ",
    "outputId": "d6f6c1ef-618e-4705-b5a0-e58f8b355cfd"
   },
   "outputs": [],
   "source": [
    "from glob import glob\n",
    "\n",
    "# Getting the path of new data\n",
    "path_list_new = [x for x in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "path_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nZvVdF7g3E1z",
    "outputId": "2b799c45-0f32-4cf1-daa1-7b196b438420"
   },
   "outputs": [],
   "source": [
    "# Getting the list of names\n",
    "lesion_list_new = [os.path.basename(os.path.dirname(os.path.dirname(y))) for y in glob(os.path.join(data_dir_train, '*','output', '*.jpg'))]\n",
    "lesion_list_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "okcqVFAA2nxK"
   },
   "outputs": [],
   "source": [
    "# Creating a dataframe\n",
    "dataframe_dict_new = dict(zip(path_list_new, lesion_list_new))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zs1vOzcnTV4S"
   },
   "outputs": [],
   "source": [
    "# Get Existing images in Dataframe\n",
    "path_list=[]\n",
    "lesion_list=[]\n",
    "for name in class_names:\n",
    "  for file in data_dir_train.glob(name+'/*.jpg'):\n",
    "    path_list.append(str(file))\n",
    "    lesion_list.append(name)\n",
    "\n",
    "dataframe_dict_original=dict(zip(path_list,lesion_list))\n",
    "original_df=pd.DataFrame(list(dataframe_dict_original.items()),columns=['Path','Label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "njzBxTNT2nxK"
   },
   "outputs": [],
   "source": [
    "df2 = pd.DataFrame(list(dataframe_dict_new.items()),columns = ['Path','Label'])\n",
    "new_df = pd.concat([original_df,df2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 397
    },
    "id": "5j45rmxd2nxK",
    "outputId": "c21b0675-b616-4fc3-ba5b-2fb46eee262d"
   },
   "outputs": [],
   "source": [
    "new_df['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9NirFBvGPmgI"
   },
   "source": [
    "So, now we have added 500 images to all the classes to maintain some class balance. We can add more images as we want to improve training process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9EnspeMbRWNs"
   },
   "source": [
    "#### **Todo**: Train the model on the data created using Augmentor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hFcj1XgndRWz"
   },
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "img_height = 180\n",
    "img_width = 180"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0haOU11Ey8ey"
   },
   "source": [
    "#### **Todo:** Create a training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H4ZY11judRWz",
    "outputId": "0409ca7c-068a-4c5f-fd93-8699f08d350b"
   },
   "outputs": [],
   "source": [
    "train_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'training',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mwNJVDuBP5kf"
   },
   "source": [
    "#### **Todo:** Create a validation dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TX191d_3dRW0",
    "outputId": "395f61f6-cf25-4d93-bd49-2f331f0e3050"
   },
   "outputs": [],
   "source": [
    "val_ds = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "  data_dir_train,\n",
    "  seed=123,\n",
    "  validation_split = 0.2,\n",
    "  subset = 'validation',\n",
    "  image_size=(img_height, img_width),\n",
    "  batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1nvaaPvAxzth"
   },
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "train_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\n",
    "val_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaoWeOEpVjqH"
   },
   "source": [
    "**Build Model with the imbalance data :**\n",
    "\n",
    "**Model 3**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ch0MuKvFVr7O"
   },
   "outputs": [],
   "source": [
    "model3 = Sequential([\n",
    "  layers.Rescaling(1./255),\n",
    "  layers.Conv2D(16, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(32, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Conv2D(64, 3, padding='same', activation='relu'),\n",
    "  layers.MaxPooling2D(),\n",
    "  layers.Dropout(0.2),\n",
    "  layers.Flatten(),\n",
    "  layers.Dense(128, activation='relu'),\n",
    "  layers.Dense(classes)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Bu5N9LxkVx1B"
   },
   "source": [
    "#### Compiling the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H47GWmLbdRW1"
   },
   "outputs": [],
   "source": [
    "model3.compile(optimizer='adam',\n",
    "               loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "               metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9gS-Y1bJV7uy"
   },
   "source": [
    "#### Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fcV6OdI4dRW1",
    "outputId": "7b2cecf2-4a7f-4c9b-b340-536859456bc9"
   },
   "outputs": [],
   "source": [
    "epochs = 30\n",
    "history_2 = model3.fit(train_ds,\n",
    "                       validation_data=val_ds,\n",
    "                       epochs=epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "iuvfCTsBWLMp"
   },
   "source": [
    "#### Visualizing the model results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 699
    },
    "id": "lCTXwfkTdRW1",
    "outputId": "b837c23f-7052-4d05-f444-841ebea94add"
   },
   "outputs": [],
   "source": [
    "results(history_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Way4lakC4_p0"
   },
   "source": [
    "Post the augmentation and class imbalance management, training and validation accuracy has increased. The model does not overfit. This model can serve as the final model.\n",
    "\n",
    "**Training Accuracy:** 95.11 &\n",
    "**Validation Accuracy:** 84.04"
   ]
  }
 ],
 "metadata": {
  "accelerator": "TPU",
  "colab": {
   "gpuType": "V28",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
